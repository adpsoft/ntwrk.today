---
layout: post
title: "Опыт построения DPI IP/ECMP based фабрики на оборудовании Juniper QFX10k с применением symmetric hashing"
tags: juniper qfx mpls bgp evpn l3vpn vxlan dpi ips hash hashing symmetric resilient
author: "somovis"
---

В данной заметке я хочу поделится опытом построения DPI блока сети передачи данных (PoD) на оборудовании **Juniper QFX10k** являющегося частью EVPN/VXLAN фабрики с применением **IP/ECMP, symmetric hashing, resilient hashing**.

## Определения
* DPI - Deep Packet Inspection или глубокий анализ пакетов;
* IPS - Intrusion Prevention System или система предотвращения вторжений;
* ECMP - Equal-Cost Multi-Path;
* HA - High Availability или высокая доступность;
* scale-up - наращивание емкости увеличением производительности устройств(а);
* scale-out - наращивание емкости увеличением количества устройств той же или аналогичной производительности;
* edge - пограничное устройство для конкретного сегмента сети;
* fw - firewall, в нашем случае это и есть DPI устройство;
* leaf/spine - физические роли устройств в CLOS based IP фабрике.

## Вступление
*Мотивацией для написания данной заметки стало тотальное отсутствие в русскоязычном сегменте подобного материала, надеюсь, что моя заметка кому-нибудь поможет в дальнейшем.*

Порой встречаются довольно интересные задачи, вот так и мне однажды посчастливилось, когда нам понадобилось построить для защиты определенного сегмента сети и его сертификации, DPI блок СПД с применением IPS. Не буду вдаваться в подробности на этом моменте, нас же больше интересует техническое решение задачи.

Вот так выглядит целевая схема DPI блока СПД:
![target scheme png](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric.png)<br/>
[Целевая схема в PDF](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric.pdf)<br/>
Если ты, уважаемый читатель, сразу ее понял и во всем разобрался, то можешь далее не читать. Но если у тебя остались еще вопросы, то милости прошу под кат.

*Хочу обратить внимание, что данное техническое решение прорабатывалось в начале 2020 года, а схема тестировалась на разных платформах и моделях разных производителей, но сейчас уже появилось более дешевое/новое оборудование или обновление ПО для более дешевого оборудования того же производителя, которое тоже подходит для решения данной задачи, при этом, некоторое протестированное оборудование уже может быть недоступно для заказа.*

ТЗ было примерно следующим:
* Инспектировать ~500Гбит трафика при помощи IPS;
* Отказоустойчивость DPI блока СПД;
* Inline DPI;
* Сертифицированное ФСТЭК оборудование;
* Потенциальный рост - проработать масштабирование;
* Универсальный дизайн DPI блока СПД для потенциальной возможности применения различного оборудования DPI при масштабировании - все же конкурентные закупки;
* Не делать дорого.

## Размышления
Если говорить про техническое решение и посмотреть в корень задачи, то можно увидеть, что требуется IPS на ~500Гбит, резервирование и потенциальный рост.

При этом, исходя из своего опыта, общения с коллегами и производителями, могу сказать, что для решения данной задачи не так уж много производителей подходит. Я не буду их перечислять, но хочу акцентировать внимание на проблему, почему так важно, что используется IPS и почему бы не сделать большой кластер или не поставить два устройства размером с шкаф:
* У производителя X можно собрать кластер до 16 устройств, но, при этом, **трафик предназначенный IPS движку обрабатывает только одно устройство** в кластере;
* У производителя Y можно собрать кластер до 16 устройств, но, при этом, **результат работы IPS движка не синхронизируется** между устройствами в кластере и в зависимости от платформы получаем либо дроп трафика, либо пропуск трафика (зачем тогда вообще IPS?!);
* У производителя Z можно собрать кластер до 2 устройств, но, при этом, результат работы IPS движка синхронизируется, однако, **максимальная производительность одного такого устройства на IPS составляет ~800Гбит и имеет довольно высокую цену** для покупки сразу обоих устройств в комплектации с целью на ~500Гбит (помним про резервирование).

Поэтому, не долго думая, я предложил использовать 3 сетевых технологии, которые будут ключевыми для решения данной задачи:
* [IP/ECMP](https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing) - в сравнении с [MC-LAG](https://ru.wikipedia.org/wiki/MC-LAG) позволяет сэкономить количество интерфейсов (убираем ICL, QSFP28 стоят денег), отсутствие L2 и [slow protocols](https://habr.com/ru/post/180761/), наличие гибкого управления трафиком, горизонтальное масштабирование;
* [Symmetric hashing](http://docs.ruckuswireless.com/fastiron/08.0.60/fastiron-08060-l2guide/GUID-55B14BDF-20C3-4BF3-935F-9D6F1FCC903E.html) - для управления прохождением трафика в оба направления через одно и то же DPI устройство;
* [Resilient hashing](https://linkmeup.ru/blog/903/#RESILIENT_HASHING) - для предотвращения перебалансировки всего трафика при аварии одного (или более) DPI устройства.

***Рекомендую ознакомиться с данными технологиями перед дальнейшим прочтением материала.***

*Отсутствие кластеризации со стороны DPI устройств нам не повредит, но естественно будут особенности, подробнее в секции "проблемы".*

Спустя какое-то время, занимаясь тестированием DPI платформ, мы увидели оптимальное для данной задачи решение в рамках одного устройства:
* **Инспектировать ~130Гбит трафика при помощи IPS** - мало ли потребуется добавить в IPS еще какие-то паттерны;
* **4*100G интерфейса**;
* Поддержка остального требуемого функционала.
В следствии чего, мы закрепили наш выбор, что **масштабирование будет горизонтальным**, чтобы достичь требуемой емкости, а **резервирование DPI устройств будет N+1**. Этого будет достаточно для абсорбирования возможных всплесков трафика или при ожидании поставки оборудования для требуемого расширения емкости. Конечно, в этом случае мы можем потерять резервирование, поэтому, в идеале, резервирование должно быть N+2, но реальный мир суров и не все, и не всегда, можно сделать так, как хочешь именно ты.

## Высокая доступность
Прежде чем говорить о масштабировании, следует упомянуть [высокую доступность](https://en.wikipedia.org/wiki/High_availability), у данного термина есть следующее определение: "свойство системы быть защищённой и легко восстанавливаемой от небольших простоев в короткое время автоматизированными средствами.".
Не стоит путать данный термин с [надежностью](https://gosthelp.ru/text/GOST2700289Nadezhnostvtex.html).

В мире телекоммуникаций высокая доступность достигается резервированием [[1](https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%B7%D0%B5%D1%80%D0%B2%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5), [2](https://bookasutp.ru/Chapter8_1.aspx)] тех или иных компонентов.
Есть следующие виды резервирования:
* Холодный (ненагруженный) резерв - данный термин очень хорошо определяет известная в телеком сообществе шутка: "чтобы зарезервировать один микротик, нужно 3 микротика - один рядом с уже работающим и один в шкафу, пока третий на доставке.". Вот холодный резерв как раз про микротик в шкафу. Но если без шуток, то вот определение: "резервные элементы не несут нагрузки или выключены и ожидают включения.";
* Горячий (нагруженный) резерв - как ты понял, это про второй микротик, рядом с уже работающим, но не совсем. Вот четкое определение: "резервные элементы нагружены так же, как и основные.".;
* Теплый (облегченный) резерв - В данном случае второй микротик может им быть, но может и не быть. Определение: "резервные элементы нагружены меньше, чем основные.";
* Резервирование замещением - резервирование, при котором функции основного элемента передаются резервному только после отказа основного элемента. Резервирование замещением может быть с холодным, теплым или горячим резервом. Его недостатком является зависимость от надежности переключающих устройств.

Не привычно, правда? Мы ведь давно привыкли, что:
* Холодный резерв - это ЗИП или резервирование замещением;
* Горячий резерв делится на подтипы:
  * active/standby - один или более элементов не активны и ожидают;
  * active/active - все элементы активны.
* А теплый резерв и в помине не упоминается.

*Но есть ГОСТ, МЭК и прочие, в которых даются четкие определения.*

Ладно, вернемся к миру телекоммуникаций и пропустим все виды резервирования, кроме привычных нам a/s, a/a.

### active/standby
![fo a/s](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_fo-a:s.png)<br/>
Классический вариант используемый в большинстве корпоративных сетей, начиная от STP (да, его можно использовать не только как защиту от петель), резервирования шлюза средствами VRRP/HSRP и заканчивая резервированием устройства предоставляющее сервис.
Ни для кого не секрет, что в данном виде резервирования часть устройств ждет аварии/переключения, чтобы перейти из режима ожидания в активный режим.
В данном виде резервирования, как правило, используется группа из двух устройств (Cluster/MC-LAG) и этот вид резервирования больше подходит для scale-up масштабирования, потому-что других вариантов внутри группы из двух устройств просто нету.

Плюсы:
* Меньше точек входа;
* Проще поиск и устранение неисправностей;
* 

### active/active
![fo a/a](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_fo-a:a.png)<br/>

## Масштабирование
Если говорить про выбор того или иного решения, то это всегда компромиссы, поэтому, ниже я опишу различные варианты масштабирования, а так же их плюсы и минусы, примеряя их на нашу задачу.

### Заядлый инжиниринг
Это, пожалуй, самый не продуктивный и не масштабируемый способ с довольно затратным обслуживанием.

Приведу простой пример: когда-то давно, когда еще не было EVPN (за исключением проприетарного GLBP), когда нужно было зарезервировать шлюз сети, требовалось использовать VRRP/HSRP на группе маршрутизаторов, при этом, только один из маршрутизаторов в данной сети мог быть активным для передачи трафика в направлении из данной сети (исключаем задачу с растянутым VLAN между разными площадками, активным VRRP на каждой площадке и фильтрации VRRP mcast/unicast между площадками). Поэтому, еще тогда придумали псевдо active/active, назначая активными разные маршрутизаторы для разных VLAN (точнее, разные приоритеты для разных VRRP Groups), таким образом получилось, что трафик из VLAN X шел в маршрутизатор 1, а трафик из VLAN Y шел в маршрутизатор 2, и так далее.

Если же мы говорим про управление трафиком между разными сегментами СПД, то это потребует дополнительных маркеров, по которым потом потребуется работать всю жизнь, а не единоразово их применить на сети и забыть навсегда. К тому же, со временем, при масштабировании, придется вносить изменения в маркировку и это вызовет перебалансировку трафика. Не говоря про сложность данного решения в автоматическом режиме, человеку, который только увидит документацию/конфигурацию, будет крайне не просто искать и исправлять потенциально возникшую проблему.
В нашем случае мы имеем >100k активных SRC IP адресов, разбросанных по всей сети (примерно ~10k префиксов) и им всем нужен доступ до сегмента, который мы защищаем. Поэтому, сказать какие маркеры применить на префикс, сколько полосы по факту будут утилизировать SRC IP адреса за конкретным префиксом и сколько IP адресов из префикса активно, и сколько будет активно завтра - практически невозможно, а сложность решения ты поймешь в секции "проблемы".
В итоге мы сразу же отказались от данной опции.

### scale-up
![scale-up](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_scale-up.png)<br/>
Еще одна опция из прошлого, когда практически любая корпоративная и телекоммуникационная компания для увеличения емкости тех или иных ресурсов, просто покупала бОльший компонент, будь то шасси маршрутизатора, коммутационная фабрика маршрутизатора, линейная карта маршрутизатора или целиком само устройство.

Конечно, у данного решения есть свои плюсы:
* **Меньше точек входа** - настраивается одно устройство, вместо 8;
* Если сегодня использовали 2/8 слотов, а расширение предстоит через пару лет, то можно потом докупить линейные/сервисные/коммутационные карты и установить в свободные слоты;
* Как правило, **потребляет меньше электроэнергии**, если сравнивать одно модульное устройство **в максимальной комплектации** с количеством не модульных устройств, которые могут обеспечить паритет по количеству интерфейсов, масштабированию и функционалу;
* Как правило, **меньше в размере**, если сравнивать одно модульное устройство **в максимальной комплектации** с количеством не модульных устройств, которые могут обеспечить паритет по количеству интерфейсов, масштабированию и функционалу;
* Проще обновление ПО, так как модули управления обычно зарезервированны, но с ISSU всегда есть риск и повышается вес SPOF;
* В некоторых случаях **один сервисный контракт покрывает все компоненты** модульного устройства.

Но есть и минусы:
* **SPOF** - одна точка отказа для всех компонентов (как говорится: "чем больше шкаф - тем громче падает!");
* Если нужно всего 2/8 слотов, то **занимает больше места**, чем количество не модульных устройств, которые могут обеспечить паритет по количеству интерфейсов, масштабированию и функционалу;
* Если нужно всего 2/8 слотов, то **потребляет больше электроэнергии**, чем количество не модульных устройств, которые могут обеспечить паритет по количеству интерфейсов, масштабированию и функционалу;
* **Сложнее поиск и исправление неисправностей из-за архитектуры модульного устройства**, так как она больше похожа на дизайн CLOS сетей, но может и отличаться от другого модульного устройства, даже в рамках одного производителя;
* Сложнее обновление, вплоть до полной замены устройства, что стоит дорого и может вызвать отказ в обслуживании сервисов;
* Привязка к одному производителю при обновлении - отсутствие конкуренции, потенциально выше стоимость и выше вес SPOF.

### scale-out
![scale-out](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_scale-out.png)<br/>
Горизонтальное масштабирование стало стандартом во многих отраслях за последние 10 лет, будь то масштабирование СПД, приложения или промышленного производства.

Плюсы:
* **Меньше SPOF**, так как производитель/платформа/модель/компоненты могут отличаться;
* Если нужно несколько устройств, то **занимает меньше места**, чем модульное устройство, которое может обеспечить паритет по количеству интерфейсов, масштабированию и функционалу;
* Если нужно несколько устройств, то **потребляет меньше электроэнергии**, чем модульное устройство, которое может обеспечить паритет по количеству интерфейсов, масштабированию и функционалу;
* **Проще поиск и исправление неисправностей**, так как архитектура одночипового коммутатора в разы проще, чем архитектура модульного устройства;
* **Безопаснее обновление ПО**, так как устройства независимы и могут резервировать друг-друга;
* **Проще добавление новых устройств**, когда потребуется масштабирование, так как в большинстве случаев *просто добавь еще* N устройств;
* Возможность использовать разных производителей и разных компонентов - привнесение конкуренции, потенциально ниже стоимость и меньше вес SPOF.

Минусы:
* **Больше точек входа** - настраивается 8 устройств, вместо одного (но кого это испугает в эпоху автоматизации?!);
* **Сложнее целевой дизайн**, так как используется бОльшее количество технологий;
* Так как используется бОльшее количество технологий, то **увеличивается вероятность отказа**, так как потенциально в каждой технологии может быть ошибка (код пишут люди, а люди совершают ошибки).

#### Cluster
![cluster](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_cluster.png)<br/>
А вот и всеми любимые кластеры, наконец-то!
Но не спешу радовать, мы будем говорить про кластеры в контексте DPI.

Кластер можно частично отнести к дизайну scale-out, так как позволяет масштабировать уже рабочий кластер добавляя в него устройства. Но каждый кластер лимитирован тем или иным ограничением, включая количество устройств и жестко привязывается к конкретному производителю, а иногда и к платформе/модели устройства, поэтому, исчерпав ресурсы кластера, понадобится строить рядом еще один (чем-то похоже на дизайн PoD, когда исчерпав ресурсы, строится рядом еще один).

Из плюсов сюда можно отнести следующее:
* Централизованное управление и мониторинг (но не всегда и не везде);
* Синхронизацию состояний потоков;
* Синхронизацию конфигураций устройств (это точно очень нужно ли в эпоху автоматизации?!)

Конечно кластер имеет свои существенные недостатки, например:
* Наш любимый **SPOF**;
* **Отсутствие синхронизации результата работы IPS движка** у большинства известных производителей;
* Другие недостатки, о которых я писал в секции "размышления", в начале данной заметки.

Для решения текущей задачи данный вариант нам не подошел, но, не исключено, что для другой задачи он подойдет.
Хотя, после решения данной задачи, задаешься вопросом: "зачем?!".

#### MC-LAG L2 Transparent
![mlag-l2-transparent](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_mlag-l2-transparent.png)<br/>
#### MC-LAG L2 Switched
![mlag-l2-switched](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_mlag-l2-switched.png)<br/>

#### MC-LAG L3 Routed w/ BGP
![mlag-l3-routed](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_mlag-l3-routed.png)<br/>

#### ECMP w/ BGP
![ecmp-v1](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_ecmp-v1.png)<br/>

![ecmp-v2](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_ecmp-v2.png)<br/>


##### Tunneling GRE/IP-IP

##### BGP communities

## Проблемы

## Конфигурация

## Заключение
С улыбкой и болью вспоминаю фразу из притчи "о доверии (вендорам)" Марата Сибгатулина с linkmeetup: "**на интеграционные тесты вендора не полагайся - сам организуй синтетические и продуктивные тесты.**".

Что бы тебе не говорил тот или иной производитель, какие-бы заключения самостоятельного тестирования не показывал, всегда могут найтись отклонения в ревизии hardware, в различном software, ошибках в software, в наличии включенных и/или выключенных тех или иных особенностях, которые могут напрямую влиять на исполнение решения поставленной задачи, поэтому, собирать лабораторную среду, даже для синтетических тестов, нужно 1:1, как планируется сделать в продуктивной среде.

И все же, в итоге мы получили отказоустойчивую DPI фабрику с возможностью горизонтального масштабирования.

## Благодарности
Спасибо name1 за вычитку и правки

## Ссылки

### Общие подходы к балансировке:
* [Доклад Игоря Васильева про балансировку трафика](https://www.youtube.com/watch?v=iZavvatyDb8)
* [Статья про ECMP и балансировку в ДЦ от Марата Сибгатулина](https://linkmeup.ru/blog/903/)

### Про hashing:
* [Nvidia: Equal Cost Multipath Load Sharing - Hardware ECMP](https://docs.nvidia.com/networking-ethernet-software/cumulus-linux-40/Layer-3/Equal-Cost-Multipath-Load-Sharing-Hardware-ECMP/)
* [Ruckus: Symmetric load balancing](http://docs.ruckuswireless.com/fastiron/08.0.60/fastiron-08060-l2guide/GUID-55B14BDF-20C3-4BF3-935F-9D6F1FCC903E.html)
* [Consistent Hash Rings Explained Simply](https://akshatm.svbtle.com/consistent-hash-rings-theory-and-implementation)
* [Google: Maglev: A Fast and Reliable Software Network Load Balancer](https://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/44824.pdf)

### Про UCMP:
* [Unequal-Cost Multipath with BGP DMZ Link Bandwidth](https://blog.ipspace.net/2021/06/ucmp-bgp-link-bandwidth.html)
* [BGP Link Bandwidth Extended Community](https://datatracker.ietf.org/doc/html/draft-ietf-idr-link-bandwidth-07)

### Про дизайн сетей в ДЦ:
* [И еще одна статья от Марата Сибгатулина, но уже про дизайн сетей в ДЦ](https://linkmeup.ru/blog/1261/)
