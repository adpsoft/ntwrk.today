---
layout: post
title: "Опыт построения DPI IP/ECMP based фабрики на оборудовании Juniper QFX10k с применением symmetric hashing"
tags: juniper qfx mpls bgp evpn l3vpn vxlan dpi ips hash hashing symmetric resilient
author: "somovis"
---

В данной заметке я хочу поделится опытом построения DPI блока сети передачи данных (PoD) на оборудовании **Juniper QFX10k** являющегося частью EVPN/VXLAN фабрики с применением **IP/ECMP, symmetric hashing, resilient hashing**.

## Определения
* DPI - Deep Packet Inspection или глубокий анализ пакетов;
* IPS - Intrusion Prevention System или система предотвращения вторжений;
* ECMP - Equal-Cost Multi-Path;
* scale-up - наращивание емкости увеличением производительности устройств(а);
* scale-out - наращивание емкости увеличением количества устройств той же или аналогичной производительности;
* edge - пограничное устройство для конкретного сегмента сети;
* fw - firewall, в нашем случае это и есть DPI устройство;
* leaf/spine - физические роли устройств в CLOS based IP фабрике.

## Вступление
*Мотивацией для написания данной заметки стало тотальное отсутствие в русскоязычном сегменте подобного материала, надеюсь, что моя заметка кому-нибудь поможет в дальнейшем.*

Порой встречаются довольно интересные задачи, вот так и мне однажды посчастливилось, когда нам понадобилось построить для защиты определенного сегмента сети и его сертификации, DPI блок СПД с применением IPS. Не буду вдаваться в подробности на этом моменте, нас же больше интересует техническое решение задачи.

Вот так выглядит целевая схема DPI блока СПД:
![target scheme png](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric.png)
[Целевая схема в PDF](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric.pdf)<br/>
Если ты, уважаемый читатель, сразу ее понял и во всем разобрался, то можешь далее не читать. Но если же тебе интересно, то милости прошу под кат.

*Хочу обратить внимание, что данное техническое решение прорабатывалось в начале 2020 года, а схема тестировалась на разных платформах и моделях разных производителей, но сейчас уже появилось более дешевое/новое оборудование или обновление ПО для более дешевого оборудования того же производителя, которое тоже подходит для решения данной задачи, при этом, некоторое протестированное оборудование уже может быть недоступно для заказа.*

ТЗ было примерно следующим:
* Инспектировать ~500Гбит трафика при помощи IPS;
* Отказоустойчивость DPI блока СПД;
* Inline DPI;
* Сертифицированное ФСТЭК оборудование;
* Потенциальный рост - проработать масштабирование;
* Универсальный дизайн DPI блока СПД для потенциальной возможности применения различного оборудования DPI при масштабировании - все же конкурентные закупки;
* Не делать дорого.

## Размышления
Если говорить про техническое решение и посмотреть в корень задачи, то можно увидеть, что требуется IPS на ~500Гбит, резервирование и потенциальный рост.

При этом, исходя из своего опыта, общения с коллегами и производителями, могу сказать, что для решения данной задачи не так уж много производителей подходит. Я не буду их перечислять, но хочу акцентировать внимание на проблему, почему так важно, что используется IPS и почему бы не сделать большой кластер или не поставить два устройства размером с шкаф:
* У производителя X можно собрать кластер до 16 устройств, но, при этом, **трафик предназначенный IPS движку обрабатывает только одно устройство** в кластере;
* У производителя Y можно собрать кластер до 16 устройств, но, при этом, **результат работы IPS движка не синхронизируется** между устройствами в кластере и в зависимости от платформы получаем либо дроп трафика, либо пропуск трафика (зачем тогда вообще IPS?!);
* У производителя Z можно собрать кластер до 2 устройств, но, при этом, результат работы IPS движка синхронизируется, однако, **максимальная производительность одного такого устройства на IPS составляет ~800Гбит и имеет довольно высокую цену** для покупки сразу обоих устройств в комплектации с целью на ~500Гбит (помним про резервирование).

Поэтому, не долго думая, я предложил использовать 3 сетевых технологии, которые будут ключевыми для решения данной задачи:
1. IP/ECMP - в сравнении с MC-LAG позволяет сэкономить количество интерфейсов (убираем ICL), отсутствие L2 и slow protocols, наличие гибкого управления трафиком, горизонтальное масштабирование;
2. symmetric hashing - для управления прохождением трафика в оба направления через одно и то же DPI устройство;
3. resilient hashing - для предотвращения перебалансировки всего трафика при аварии одного (или более) DPI устройства.

*Отсутствие кластеризации со стороны DPI устройств нам не повредит, но естественно будут особенности, подробнее в секции "проблемы".*

Спустя какое-то время, занимаясь тестированием DPI платформ, мы увидели оптимальное для данной задачи решение в рамках одного устройства:
* Инспектировать ~130Гбит трафика при помощи IPS - мало ли потребуется добавить в IPS еще какие-то паттерны;
* 4*100G интерфейса;
* Поддержка остального требуемого функционала.

В следствии чего, мы закрепили наш выбор, что масштабирование конечно будет горизонтальным, чтобы достичь требуемой емкости, а резервирование DPI устройств будет N+1. Этого будет достаточно для абсорбирования возможных всплесков трафика или при ожидании поставки оборудования для требуемого расширения емкости. Конечно, в этом случае мы можем потерять резервирование, поэтому, в идеале, резервирование должно быть N+2, но реальный мир суров и не все, и не всегда, можно сделать так, как хочешь именно ты.

## Высокая доступность


### active/standby

![fo a/s](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_fo-a:s.png)

### active/active

![fo a/a](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_fo-a:a.png)

## Масштабирование
Если говорить про выбор того или иного решения, то это всегда компромиссы, поэтому, ниже я опишу различные варианты масштабирования, а так же их плюсы и минусы, примеряя их на нашу задачу.

### Заядлый инжиниринг
Это, пожалуй, самый не продуктивный и не масштабируемый способ с довольно затратным обслуживанием.

Приведу простой пример: когда-то давно, когда еще не было EVPN (за исключением проприетарного GLBP), когда нужно было зарезервировать шлюз сети, требовалось использовать VRRP/HSRP на группе маршрутизаторов, при этом, только один из маршрутизаторов в данной сети мог быть активным для передачи трафика (исключаем задачу с растянутым VLAN между разными площадками, активным VRRP на каждой площадке и фильтрации VRRP mcast/unicast между площадками). Поэтому, еще тогда придумали псевдо active/active, назначая активными разные маршрутизаторы для разных VLAN (точнее, разные приоритеты для разных VRRP Groups), таким образом получилось, что трафик из VLAN X шел в маршрутизатор 1, а трафик из VLAN Y шел в маршрутизатор 2, и так далее.

Если же мы говорим про управление трафиком между разными сегментами СПД, то это потребует дополнительных маркеров, по которым потом потребуется работать всю жизнь, а не единоразово их применить на сети и забыть навсегда. К тому же, со временем, при масштабировании, придется вносить изменения в маркировку и это вызовет перебалансировку трафику. Не говоря про сложность данного решения в автоматическом режиме, человеку, который только увидит документацию/конфигурацию, будет крайне не просто искать и исправлять потенциально возникшую проблему.
В нашем случае мы имеем >100k SRC IP адресов, при этом, всего ~10k префиксов и сказать какие маркеры применить на префикс, сколько полосы по факту будут утилизировать SRC IP адреса за конкретным префиксом, практически невозможно, а сложность решения ты поймешь в секции "проблемы".
Поэтому, мы сразу же отказались от данной опции.

### scale-up
![scale-up](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_scale-up.png)
Еще одна опция из прошлого, когда практически любая корпоративная и телекоммуникационная компания для увеличения емкости тех или иных ресурсов, просто покупала бОльший компонент, будь то шасси маршрутизатора, коммутационная фабрика маршрутизатора, линейная карта маршрутизатора или целиком само устройство.

### scale-out
![scale-out](/images/2021-07-15-juniper-qfx10k-ecmp-based-dpi-fabric_scale-out.png)

#### Cluster

#### MC-LAG L2 Transparent

#### MC-LAG L2 Switched

#### MC-LAG L3 Routed w/ BGP

#### ECMP w/ BGP

## Проблемы

## Конфигурация

## Заключение
С улыбкой и болью вспоминаю фразу из притчи "о доверии (вендорам)" Марата Сибгатулина с linkmeetup: "**на интеграционные тесты вендора не полагайся - сам организуй синтетические и продуктивные тесты.**".

Что бы тебе не говорил тот или иной производитель, какие-бы заключения самостоятельного тестирования не показывал, всегда могут найтись отклонения в ревизии hardware, в различном software, ошибках в software, в наличии включенных и/или выключенных тех или иных особенностях, которые могут напрямую влиять на исполнение решения поставленной задачи, поэтому, собирать лабораторную среду, даже для синтетических тестов, нужно 1:1, как планируется сделать в продуктивной среде.

И все же, в итоге мы получили отказоустойчивую DPI фабрику с возможностью горизонтального масштабирования.

## Благодарности
Спасибо name1 за вычитку и правки

## Ссылки
<b id="f1">1</b>. [Отличный доклад Игоря Васильева про балансировку трафика](https://www.youtube.com/watch?v=iZavvatyDb8) [↩](#a1)<br/>
<b id="f2">2</b>. [Отличная статья про ECMP и балансировку в ДЦ от Марата Сибгатулина](https://linkmeup.ru/blog/903/) [↩](#a2)<br/>
<b id="f3">3</b>. [И еще одна статья от Марата Сибгатулина, но уже про дизайн сетей в ДЦ](https://linkmeup.ru/blog/1261/) [↩](#a3)<br/>
<b id="f4">4</b>. [BGP Link Bandwidth Extended Community](https://datatracker.ietf.org/doc/html/draft-ietf-idr-link-bandwidth-07) [↩](#a4)<br/>
